# @package _global_

defaults:
  - override /model: am.yaml
  - override /env: tsp.yaml
  - override /callbacks: default.yaml
  - override /trainer: default.yaml
  - override /logger: wandb.yaml

env:
  generator_params:
    num_loc: 50

logger:
  wandb:
    project: "rl4co"
    tags: ["am", "${env.name}"]
    group: ${env.name}${env.generator_params.num_loc}
    name: am-${env.name}${env.generator_params.num_loc}


model:
  batch_size: 64
  val_batch_size: 1024
  test_batch_size: 1024
  train_data_size: 640   # train_data_size만큼의 문제 인스턴스가 만들어지고, batch_size만큼의 데이터를 train_data_size / batch_size만큼 학습함. 이 과정을 epoch만큼 반복.
  val_data_size: 10_000
  test_data_size: 10_000
  optimizer_kwargs:
    lr: 1e-4
    weight_decay: 1e-6
  lr_scheduler:
    "MultiStepLR"
  lr_scheduler_kwargs:
    milestones: [80, 95]
    gamma: 0.1

trainer:
  max_epochs: 100  # epochs

seed: 1234

